## Домашнее задание к занятию "6.6. Troubleshooting"

---
### Задача 1
Перед выполнением задания ознакомьтесь с документацией по администрированию MongoDB.
Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её нужно прервать.
Вы как инженер поддержки решили произвести данную операцию:

Напишите список операций, которые вы будете производить для остановки запроса пользователя
предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

---
### Ответ:
 Документация

[https://www.mongodb.com/docs/manual/administration/] 

1) Для решения  проблемы  необходимо включить профайлер на текущей ноде

- либо следующей командой

       db.setProfilingLevel(1, { slowms: 180000, sampleRate: 0.42 })
       где 
          1        - уровень профилирования. Профайлер собирает данные для операций, которые занимают больше времени, чем значение slowms .
          180000   - slowms - Порог срабатывания для попадания в лог. Время операции больше 3 минут. Измеряется в  ms. 
          0.42     - sampleRate - частота дискретизации ( доля медленных операций,которые должны попасть в лог ( диапазон от 0 до 1).
 
- либо добавить в  файл конфигурации строки (не рекомендовано из-за снижения  производительности БД) 
  
       operationProfiling:             # анализ эффективности
            mode: slowOp               # operationProfiling mode 
            slowOpThresholdMs: 180000  # Определяется как временной порог медленной скорости запроса, запросы, превышающие это время, являются медленными запросами и будут записаны в журнал, по умолчанию 100
            slowOpSampleRate: 0.42     # Доля медленных операций, которые должны попасть в лог ( диапазон от 0 до 1).     
                

2) Также можно использовать команду  db.currentOp(),  

- При отсутствии кластера необходимо запустить  команду на ноде с запущенным демоном mongod

                 db.currentOp(
                     {
                         "active" : true,
                         "secs_running"  : { "$gte" : 180 },     //  где db1 - имя БД ; 180 - время в секундах)
                         "ns" : /^db1\./
                     }
                 )      
                 

- Если мы имеем кластерное решение с шардами, то можно использовать двухэтапную агрегацию. 
Чтобы получить результат, относящийся только к запросам клиента, запущенным на конкретном экземпляре mongos
команду агрегации необходимо запускать  именно на данной ноде, где клиент запустил запрос.
        
        
                use admin
                db.aggregate ( [
                   // Stage 1:
                   {  
                       $currentOp : {  
                           "allUsers" : true, 
                           "localOps" : true 
                       } 
                   },
                   // Stage 2:
                   { 
                       $match : {
                          "active" : true,
                          "secs_running"  : { "$gte" : 180 },    //  где db1 - имя БД ; 180 - время в секундах) 
                          "ns" : /^db1\./
                      } 
                   }
               ] )


3) После нахождения тормозящей CRUD-операции,  можно отменить её выполнение командой 
   и сообщить о ней разработчику для исправления ситуации:

         db.killOp(opid)     //  где  opid -  ID операции. 

4) Найти все остальные медленные запросы  можно также

         - с помощью вышеуказанного профайлера;
         - с помощью explain(‘executionStats’) построить план запроса;

5) Перманентный вариант решения проблемы - поставить БД на мониторинг, включив монитор FreeMonitoring, 
   где  можно просмотреть последние 24 часа активности в среде с диаграммами.
   Сама команда вернет URL-адрес, по которому  можно просмотреть показатели.

        а) Либо через интерфейс командой 
            db.enableFreeMonitoring()  
        б) Либо с помощью командной строки  
            -enableFreeMonitoring 
        в) Либо с помощью  добавления опции "cloud.monitoring.free.state:  on" в файл конфигурации /etc/mongod.conf и
           далее перезапуском экземпляра MongoDB 
             #  service mongodnetbrain start
 
 
---
### Задача 2
Перед выполнением задания познакомьтесь с документацией по Redis latency troobleshooting.
Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная 
и увеличивается пропорционально количеству реплик сервиса.

При масштабировании сервиса до N реплик вы увидели, что:

Сначала рост отношения записанных значений к истекшим, а затем Redis блокирует операции записи.
Как вы думаете, в чем может быть проблема?

---
### Ответ:

[https://redis.io/docs/reference/optimization/latency/]
[https://www.mo4tech.com/how-to-solve-the-key-expiration-problem-in-redis.html]
[https://russianblogs.com/article/8432940100/]

1) Отключаем huges pages в ядре ОС

       # echo never > /sys/kernel/mm/transparent_hugepage/enabled

2) Включаем  логирование медленных запросов

       а) Либо добавляем следующие директивы  в  redis.conf  - файле  конфигурации СУБД Redis.

       slowlog-log-slower-than  10000   -  порог времени выполнения  запроса в ms для попадание в slowlog  
       slowlog-max-len   100 - кол-во записей в  журнале медленных запросов .

       б) либо с помощью  команды

       # redis 127.0.0.1:6379> CONFIG SET slowlog-log-slower-than 10000   (10000 microseconds )
       # redis 127.0.0.1:6379> CONFIG SET slowlog-max-len  100

3) Проверяем результат

       # redis 127.0.0.1:6379> CONFIG GET slowlog-log-slower-than
       # redis 127.0.0.1:6379> CONFIG GET slowlog-max-len

4) Получаем список медленных запросов, ограничивая их количество
    
       # redis 127.0.0.1:6379> SLOWLOG GET 100

       Каждая запись Slow Log состоит из 6 основных частей.
       1) Уникальный идентификатор записи в журнале.
       2) Временная метка unix, обозначающая время добавления записи.
       3) Обозначает время выполнения запроса в микросекундах.
       4) Это массив, содержащий аргументы указанной команды.
       5) Это адрес клиента и порт, выдавший команду ( Обычно 127.0.1.1:44118 ).
       6) Имя клиента, указанное командой client setname.

5) Включаем мониторинг задержки запросов. ПО умолчанию порог 0ms. Установим порог на 100ms.
   Эта указание серверу регистрировать все события, блокирующие сервер, на время, равное или превышающее 100 миллисекунд.

       а) Либо добавляем следующую директиву  в  redis.conf  - файле  конфигурации СУБД Redis.
 
          latency-monitor-threshold 100

       б) Либо командой

       # redis 127.0.0.1:6379> CONFIG SET latency-monitor-threshold 100

               
7) Смотрим все события вызывающие задержку

       # redis 127.0.0.1:6379> LATENCY LATEST 

8) Исправление ситуации 

       Отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная.
       БД REDIS очищает ключи двумя способами параллельно - пассивным и активным.
   
       При пассивной очистке ключи не будут обрабатываться, даже если истечет срок их действия, 
       а удалятся только, когда к ним произойдет обращение в запросах.

       При активной очистке  параметр ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP  по умолчанию установлен в  значение 20, 
       а процесс выполняется десять раз в секунду, Таким образом обычно активная очистка очищает только 200 ключей в секунду.

       Однако алгоритм активной (периодической) очистки является адаптивным и зацикливается, если обнаружит, 
       что более 25% ключей уже просрочены в наборе выбранных ключей. 

       Если в базе данных есть много-много ключей, срок действия которых истекает в одну и ту же секунду, 
       и они составляют не менее 25% текущей совокупности ключей с установленным сроком действия,
       то процесс активной очистки зациклится.

       В этом состоянии  Однопоточная СУБД Redis может полностью заблокировать клиентский доступ  к ключам на время 
       пока  процент ключей, срок действия которых уже истек, не станет ниже 25%.
     
       Какие действия предпринять ?

          1) Параметр появления новых истекших ключей ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP необходимо уменьшить,например до 5,
             чтобы дать возможность клиентам СУБД Redis выполнять операции с ключами во время пауз между периодами 
             активнстью алгоритма очистки.     

          2) Скорее всего при выполнении записи ключей в базу не был задан параметр истечения срока действия ключа. 
             Для иcправления ситуации необходимо в базе принудительно установить Тайм-аут TTL 
             для всех ключей с отсутствующим сроком истечения.
             EXPIRE  mykey <TTL в сек >  NX   
      
             # redis 127.0.0.1:6379> EXPIRE mykey 3000
             (целое число) 1
             # redis 127.0.0.1:6379> TTL mykey
             (целое число) 3000
             # redis 127.0.0.1:6379>

          3) Выборочно удалить ключи, задав отрицательный TTL 
             EXPIRE  mykey -1     
      
             # redis 127.0.0.1:6379> SET mykey "Hello"
             "OK"
             # redis 127.0.0.1:6379> EXISTS mykey
             (целое число) 1
             # redis 127.0.0.1:6379> EXPIRE mykey -1
             (целое число) 1
             # redis 127.0.0.1:6379> EXISTS mykey
             (целое число) 0
             # redis 127.0.0.1:6379>

         4) Сообщить программисту, чтобы он внес  изменения в код, проверив наличие  TTL в операции добавления ключей в БД Redis ,
           например, SET  mykey EX <time_to_live_in_seconds>
      


---
### Задача 3
- Перед выполнением задания познакомьтесь с документацией по "Common Mysql errors" 
(https://dev.mysql.com/doc/refman/8.0/en/common-errors.html) .
- Вы подняли базу данных MySQL для использования в гис-системе. 
При росте количества записей, в таблицах базы, пользователи начали жаловаться на ошибки вида:

      InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '

- Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?
---
### Ответ:
Налицо 5-й вариант проблем - нарушение обмена с сервером MySQL.


[https://stackoverflow.com/questions/10563619/error-code-2013-lost-connection-to-mysql-server-during-query]

---
### Задача 4
- Перед выполнением задания ознакомьтесь со статьей "Common PostgreSQL errors"  
(https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors) .
- Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, 
что эта СУБД работает с большим объемом данных лучше, чем MySQL.
- После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. 
В dmesg вы видите, что:  ... postmaster invoked oom-killer

Как вы думаете, что происходит?
Как бы вы решили данную проблему?

---
### Ответ:

grep "Out of memory" /var/log/messages 

Если вы получите уведомление о том, что произошло событие «недостаточно памяти», процесс OOM-killer уже выполнил свою работу, 
и вы увидите, что память освобождена.
Итак, чтобы выяснить, что произошло, нам придется просмотреть журналы
less /var/log/kern.log|grep -v 'UFW BLOCK' 
dmesg --ctime --color=always | grep -v 'UFW BLOCK'), чтобы узнать, что произошло.


Сначала выясним идентификатор (PID) процесса postmaster:

         pgrep -f postmaster
         3234.

Затем настраиваем  OOM Killer так, чтобы он  и не думал убить процесс с PID 3234 — записываем в файл oom_adj 
в соответствующем каталоге (/proc/PID/oom_adj) магическое число -17 (OOM score):
     
        echo -17 > /proc/3234/oom_adj 

Проверим заданные настройки:

        cat  /proc/3234/oom_adj 
        -17 



[https://support.hypernode.com/en/troubleshooting/performance/how-to-debug-out-of-memory-oom-events]

[https://haydenjames.io/how-to-diagnose-oom-errors-on-linux-systems/]

[https://postgrespro.ru/list/thread-id/2426258]

      typical reason for oom-kill are too high values for work_mem.

[https://postgrespro.ru/docs/postgresql/9.6/runtime-config-resource]
  
work_mem (integer)
Задаёт объём памяти, который будет использоваться для внутренних операций сортировки 
и хеш-таблиц, прежде чем будут задействованы временные файлы на диске. 
Значение по умолчанию — четыре мегабайта (4MB). 
Заметьте, что в сложных запросах одновременно могут выполняться несколько операций 
сортировки или хеширования, и при этом указанный объём памяти может использоваться 
в каждой операции, прежде чем данные начнут вытесняться во временные файлы.
Кроме того, такие операции могут выполняться одновременно в разных сеансах. 
Таким образом, общий объём памяти может многократно превосходить значение work_mem;
это следует учитывать, выбирая подходящее значение.
Операции сортировки используются для ORDER BY, DISTINCT и соединений слиянием. 
Хеш-таблицы используются при соединениях и агрегировании по хешу,
а также обработке подзапросов IN с применением хеша.