## Домашнее задание к занятию "6.6. Troubleshooting"

---
### Задача 1
Перед выполнением задания ознакомьтесь с документацией по администрированию MongoDB.
Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её нужно прервать.
Вы как инженер поддержки решили произвести данную операцию:

Напишите список операций, которые вы будете производить для остановки запроса пользователя
предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

---
### Ответ:
 Документация

[https://www.mongodb.com/docs/manual/administration/] 

1) Для решения  проблемы  необходимо включить профайлер на текущей ноде

- либо следующей командой

       db.setProfilingLevel(1, { slowms: 180000, sampleRate: 0.42 })
       где 
          1        - уровень профилирования. Профайлер собирает данные для операций, которые занимают больше времени, чем значение slowms .
          180000   - slowms - Порог срабатывания для попадания в лог. Время операции больше 3 минут. Измеряется в  ms. 
          0.42     - sampleRate - частота дискретизации ( доля медленных операций,которые должны попасть в лог ( диапазон от 0 до 1).
 
- либо добавить в  файл конфигурации строки (не рекомендовано из-за снижения  производительности БД) 
  
       operationProfiling:             # анализ эффективности
            mode: slowOp               # operationProfiling mode 
            slowOpThresholdMs: 180000  # Определяется как временной порог медленной скорости запроса, запросы, превышающие это время, являются медленными запросами и будут записаны в журнал, по умолчанию 100
            slowOpSampleRate: 0.42     # Доля медленных операций, которые должны попасть в лог ( диапазон от 0 до 1).     
                

2) Также можно использовать команду  db.currentOp(),  

- При отсутствии кластера необходимо запустить  команду на ноде с запущенным демоном mongod

                 db.currentOp(
                     {
                         "active" : true,
                         "secs_running"  : { "$gte" : 180 },     //  где db1 - имя БД ; 180 - время в секундах)
                         "ns" : /^db1\./
                     }
                 )      
                 

- Если мы имеем кластерное решение с шардами, то можно использовать двухэтапную агрегацию. 
Чтобы получить результат, относящийся только к запросам клиента, запущенным на конкретном экземпляре mongos
команду агрегации необходимо запускать  именно на данной ноде, где клиент запустил запрос.
        
        
                use admin
                db.aggregate ( [
                   // Stage 1:
                   {  
                       $currentOp : {  
                           "allUsers" : true, 
                           "localOps" : true 
                       } 
                   },
                   // Stage 2:
                   { 
                       $match : {
                          "active" : true,
                          "secs_running"  : { "$gte" : 180 },    //  где db1 - имя БД ; 180 - время в секундах) 
                          "ns" : /^db1\./
                      } 
                   }
               ] )


3) После нахождения тормозящей CRUD-операции,  можно отменить её выполнение командой 
   и сообщить о ней разработчику для исправления ситуации:

         db.killOp(opid)     //  где  opid -  ID операции. 

4) Найти все остальные медленные запросы  можно также

         - с помощью вышеуказанного профайлера;
         - с помощью explain(‘executionStats’) построить план запроса;

5) Перманентный вариант решения проблемы - поставить БД на мониторинг, включив монитор FreeMonitoring, 
   где  можно просмотреть последние 24 часа активности в среде с диаграммами.
   Сама команда вернет URL-адрес, по которому  можно просмотреть показатели.

        а) Либо через интерфейс командой 
            db.enableFreeMonitoring()  
        б) Либо с помощью командной строки  
            -enableFreeMonitoring 
        в) Либо с помощью  добавления опции "cloud.monitoring.free.state:  on" в файл конфигурации /etc/mongod.conf и
           далее перезапуском экземпляра MongoDB 
             #  service mongodnetbrain start
 
 
---
### Задача 2
Перед выполнением задания познакомьтесь с документацией по Redis latency troobleshooting.
Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная 
и увеличивается пропорционально количеству реплик сервиса.

При масштабировании сервиса до N реплик вы увидели, что:

Сначала рост отношения записанных значений к истекшим
Redis блокирует операции записи
Как вы думаете, в чем может быть проблема?

---
### Ответ:

[https://redis.io/docs/reference/optimization/latency/]


---
### Задача 3

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы, пользователи начали жаловаться на ошибки вида:
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?
---
### Ответ:
Налицо 5-й вариант проблем - нарушение обмена с сервером MySQL.


[https://stackoverflow.com/questions/10563619/error-code-2013-lost-connection-to-mysql-server-during-query]

---
### Задача 4
Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с большим объемом данных лучше, чем MySQL.
После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:
postmaster invoked oom-killer

Как вы думаете, что происходит?
Как бы вы решили данную проблему?

---
### Ответ:

grep "Out of memory" /var/log/messages 

Если вы получите уведомление о том, что произошло событие «недостаточно памяти», процесс OOM-killer уже выполнил свою работу, 
и вы увидите, что память освобождена.
Итак, чтобы выяснить, что произошло, нам придется просмотреть журналы
less /var/log/kern.log|grep -v 'UFW BLOCK' 
dmesg --ctime --color=always | grep -v 'UFW BLOCK'), чтобы узнать, что произошло.


Сначала выясним идентификатор (PID) процесса postmaster:

         pgrep -f postmaster
         3234.

Затем настраиваем  OOM Killer так, чтобы он  и не думал убить процесс с PID 3234 — записываем в файл oom_adj 
в соответствующем каталоге (/proc/PID/oom_adj) магическое число -17 (OOM score):
     
        echo -17 > /proc/3234/oom_adj 

Проверим заданные настройки:

        cat  /proc/3234/oom_adj 
        -17 



[https://support.hypernode.com/en/troubleshooting/performance/how-to-debug-out-of-memory-oom-events]

[https://haydenjames.io/how-to-diagnose-oom-errors-on-linux-systems/]

[https://postgrespro.ru/list/thread-id/2426258]

      typical reason for oom-kill are too high values for work_mem.

[https://postgrespro.ru/docs/postgresql/9.6/runtime-config-resource]
  
work_mem (integer)
Задаёт объём памяти, который будет использоваться для внутренних операций сортировки 
и хеш-таблиц, прежде чем будут задействованы временные файлы на диске. 
Значение по умолчанию — четыре мегабайта (4MB). 
Заметьте, что в сложных запросах одновременно могут выполняться несколько операций 
сортировки или хеширования, и при этом указанный объём памяти может использоваться 
в каждой операции, прежде чем данные начнут вытесняться во временные файлы.
Кроме того, такие операции могут выполняться одновременно в разных сеансах. 
Таким образом, общий объём памяти может многократно превосходить значение work_mem;
это следует учитывать, выбирая подходящее значение.
Операции сортировки используются для ORDER BY, DISTINCT и соединений слиянием. 
Хеш-таблицы используются при соединениях и агрегировании по хешу,
а также обработке подзапросов IN с применением хеша.