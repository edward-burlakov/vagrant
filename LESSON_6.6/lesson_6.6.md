## Домашнее задание к занятию "6.6. Troubleshooting"

---
### Задача 1
- Перед выполнением задания ознакомьтесь с документацией по администрированию MongoDB.
- Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её нужно прервать.
- Вы как инженер поддержки решили произвести данную операцию:

Напишите список операций, которые вы будете производить для остановки запроса пользователя
предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

---
### Ответ:
 Документация
 (https://www.mongodb.com/docs/manual/administration/)

 1) Для решения  проблемы  необходимо включить профайлер на текущей ноде

 - либо следующей командой

       db.setProfilingLevel(1, { slowms: 180000, sampleRate: 0.42 })
       где 
          1        - уровень профилирования. Профайлер собирает данные для операций, которые занимают больше времени, чем значение slowms .
          180000   - slowms - Порог срабатывания для попадания в лог. Время операции больше 3 минут. Измеряется в  ms. 
          0.42     - sampleRate - частота дискретизации ( доля медленных операций,которые должны попасть в лог ( диапазон от 0 до 1).
 
 - либо добавить в  файл конфигурации строки (не рекомендовано из-за снижения  производительности БД) 
  
       operationProfiling:             # анализ эффективности
            mode: slowOp               # operationProfiling mode 
            slowOpThresholdMs: 180000  # Определяется как временной порог медленной скорости запроса, запросы, превышающие это время, являются медленными запросами и будут записаны в журнал, по умолчанию 100
            slowOpSampleRate: 0.42     # Доля медленных операций, которые должны попасть в лог ( диапазон от 0 до 1).     
                

 2) Также можно использовать команду  db.currentOp(),  

 - При отсутствии кластера необходимо запустить  команду на ноде с запущенным демоном mongod

                 db.currentOp(
                     {
                         "active" : true,
                         "secs_running"  : { "$gte" : 180 },     //  где db1 - имя БД ; 180 - время в секундах)
                         "ns" : /^db1\./
                     }
                 )      
                 

 - Если мы имеем кластерное решение с шардами, то можно использовать двухэтапную агрегацию. 
 Чтобы получить результат, относящийся только к запросам клиента, запущенным на конкретном экземпляре mongos
 команду агрегации необходимо запускать  именно на данной ноде, где клиент запустил запрос.
        
        
                use admin
                db.aggregate ( [
                   // Stage 1:
                   {  
                       $currentOp : {  
                           "allUsers" : true, 
                           "localOps" : true 
                       } 
                   },
                   // Stage 2:
                   { 
                       $match : {
                          "active" : true,
                          "secs_running"  : { "$gte" : 180 },    //  где db1 - имя БД ; 180 - время в секундах) 
                          "ns" : /^db1\./
                      } 
                   }
               ] )


 3) После нахождения тормозящей CRUD-операции,  можно отменить её выполнение командой 
   и сообщить о ней разработчику для исправления ситуации:

         db.killOp(opid)     //  где  opid -  ID операции. 

 4) Найти все остальные медленные запросы  можно также

         - с помощью вышеуказанного профайлера;
         - с помощью explain(‘executionStats’) построить план запроса;

 5) Перманентный вариант решения проблемы - поставить БД на мониторинг, включив монитор FreeMonitoring, 
   где  можно просмотреть последние 24 часа активности в среде с диаграммами.
   Сама команда вернет URL-адрес, по которому  можно просмотреть показатели.

        а) Либо через интерфейс командой 
            db.enableFreeMonitoring()  
        б) Либо с помощью командной строки  
            -enableFreeMonitoring 
        в) Либо с помощью  добавления опции "cloud.monitoring.free.state:  on" в файл конфигурации /etc/mongod.conf и
           далее перезапуском экземпляра MongoDB 
             #  service mongodnetbrain start
 
 
---
### Задача 2
- Перед выполнением задания познакомьтесь с документацией по Redis latency troobleshooting.
  (https://redis.io/docs/reference/optimization/latency/)
- Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
- Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная 
- и увеличивается пропорционально количеству реплик сервиса.

При масштабировании сервиса до N реплик вы увидели, что:

Сначала рост отношения записанных значений к истекшим, а затем Redis блокирует операции записи.
Как вы думаете, в чем может быть проблема?

---
### Ответ:

1) Отключаем huges pages в ядре ОС

       # echo never > /sys/kernel/mm/transparent_hugepage/enabled
       # systemctl restart redis

3) Включаем  логирование медленных запросов

       а) Либо добавляем следующие директивы  в  redis.conf  - файле  конфигурации СУБД Redis.

       slowlog-log-slower-than  10000   -  порог времени выполнения  запроса в ms для попадания операции в slowlog  
       slowlog-max-len   100 - кол-во записей в  журнале медленных запросов .

       б) либо с помощью  команды

       # redis-cli  CONFIG SET slowlog-log-slower-than 10000   (10000 microseconds )
       # redis-cli  CONFIG SET slowlog-max-len  100

4) Проверяем результат

       # redis-cli  CONFIG GET slowlog-log-slower-than
       # redis-cli  CONFIG GET slowlog-max-len

5) Получаем список медленных запросов, ограничивая их количество
    
       # redis-cli  SLOWLOG GET 100

       Каждая запись Slow Log состоит из 6 основных частей.
       1) Уникальный прогрессивный идентификатор для каждой медленной записи журнала.
       2) Отметка времени unix, в которую была обработана зарегистрированная команда.
       3) Количество времени, необходимое для его выполнения, в микросекундах.
       4) Массив, из которого состоят аргументы команды.
       5) IP-адрес клиента и порт, выдавший команду ( Обычно 127.0.1.1:44118 ).
       6) Имя клиента, сли оно задано командой client setname.

6) Включаем мониторинг задержки запросов. ПО умолчанию порог 0ms. Установим порог на 100ms.
   Эта указание серверу регистрировать все события, блокирующие сервер, на время, равное или превышающее 100 миллисекунд.

       а) Либо добавляем следующую директиву  в  redis.conf  - файле  конфигурации СУБД Redis.
 
          latency-monitor-threshold 100

       б) Либо командой

       # redis 127.0.0.1:6379> CONFIG SET latency-monitor-threshold 100

               
7) Смотрим все события, вызывающие задержку

       # redis 127.0.0.1:6379> LATENCY LATEST 

8) Исправление ситуации:

   Предполагаемые  причины две:

       1) Работа кластера нарушена ( например, мастер-нода пытается и не может сохранить изменённые ключи на удаленные реплики 
          и на это время блокирует запись новых пар ключей в СУБД) 
           То есть,в этом состоянии, согласно CAP-теореме, кластер работает в режиме CP.
   
          Для устранения первой причины надо проверить и восстановить  работоспособность  процесса репликации между членами кластера.

          Рекомендую развернуть и использовать сиcтему Redis Sentinel - мониторинга и управления доступностью кластера.


       2) СУБД  не успевает очистить старые ключи.
   
       Отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная.
       БД REDIS очищает ключи двумя способами параллельно - пассивным и активным.
   
       При пассивной очистке ключи не будут обрабатываться, даже если истечет срок их действия, 
       а удалятся только, когда к ним произойдет обращение в запросах.

       При активной очистке  параметр ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP  по умолчанию установлен в  значение 20, 
       а процесс выполняется десять раз в секунду, Таким образом обычно активная очистка очищает только 200 ключей в секунду.

       Однако алгоритм активной (периодической) очистки является адаптивным и зацикливается, если обнаружит, 
       что более 25% ключей уже просрочены в наборе выбранных ключей. 

       Если в базе данных есть много-много ключей, срок действия которых истекает в одну и ту же секунду, 
       и они составляют не менее 25% текущей совокупности ключей с установленным сроком действия,
       то процесс активной очистки зациклится.

       В этом состоянии  Однопоточная СУБД Redis может полностью заблокировать клиентский доступ  к ключам на время 
       пока  процент ключей, срок действия которых уже истек, не станет ниже 25%.

        
       Для устранения второй причины :

        1) Параметр появления новых истекших ключей ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP необходимо уменьшить,например до 5,
           чтобы дать возможность клиентам СУБД Redis выполнять операции с ключами во время пауз между периодами 
           активности алгоритма очистки.     

        2) Для исключение ситуации нахождения в БД  ключей с отсутствующим параметром истечения срока действия ключа
           для таких ключей необходимо в базе принудительно установить Тайм-аут TTL

              EXPIRE  mykey <TTL в сек >  NX   
      
              # redis 127.0.0.1:6379> EXPIRE mykey 3000
              (целое число) 1
              # redis 127.0.0.1:6379> TTL mykey
              (целое число) 3000
              # redis 127.0.0.1:6379>

        3) Также можно выборочно удалить ключи, задав отрицательный TTL  
              EXPIRE  mykey -1     
      
              # redis 127.0.0.1:6379> SET mykey "Hello"
              "OK"
              # redis 127.0.0.1:6379> EXISTS mykey
              (целое число) 1
              # redis 127.0.0.1:6379> EXPIRE mykey -1
              (целое число) 1
              # redis 127.0.0.1:6379> EXISTS mykey
              (целое число) 0
              # redis 127.0.0.1:6379>

        4) Сообщить программисту, чтобы он внес  изменения в код, 
           проверив обязательноt наличие параметра TTL в операции добавления ключей в БД Redis .
           А также исключил  ситуацию, когда в БД Redis записываются ключи  со срок TTL, установленым на одну дату,
           например, SET  mykey EX <time_to_live_in_seconds> 
      

[https://www.mo4tech.com/how-to-solve-the-key-expiration-problem-in-redis.html]

[https://russianblogs.com/article/8432940100/]

---
### Задача 3
- Перед выполнением задания познакомьтесь с документацией по "Common Mysql errors" 
  (https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

- Вы подняли базу данных MySQL для использования в гис-системе. 
При росте количества записей, в таблицах базы, пользователи начали жаловаться на ошибки вида:

      InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '

- Как вы думаете, почему это начало происходить и как локализовать проблему?

- Какие пути решения данной проблемы вы можете предложить?

---
### Ответ:

Налицо 5-й тип проблем - нарушение обмена с сервером MySQL.
Это сообщение об ошибке может быть вызвано 3-мя вероятными причинами:

1) Обычно это указывает на проблемы с подключением к сети, и вам следует проверить состояние вашей сети, 
       если эта ошибка возникает часто. 
       Если сообщение об ошибке включает « during query » , это, вероятно, именно тот случай, с которым мы столкнулись.

2) Иногда форма « during query » возникает, когда миллионы строк отправляются как часть одного или нескольких запросов. 
   Если вы знаете, что это происходит, попробуйте увеличить значение параметра "net_read_timeout".
   Значение по умолчанию с 30 секунд до 60 секунд или дольше, что достаточно для завершения передачи данных.

3) Реже это может произойти, когда клиент пытается установить первоначальное соединение с сервером. В этом случае, 
   если значение параметра  "connect_timeout"  установлено всего на несколько секунд, вы можете решить проблему, 
   увеличив его до десяти секунд, возможно, больше, если у вас очень большое расстояние или медленное соединение. 
   Вы можете определить, испытываете ли вы эту более редкую причину, используя SHOW GLOBAL STATUS LIKE 'Aborted_connects'. 
   Он увеличивается на единицу за каждую первоначальную попытку подключения, которую прерывает сервер. 
   Вы можете увидеть « reading authorization packet » как часть сообщения об ошибке; если это так, 
   это также говорит о том, что именно то решение, которое нужно.


- Если причина не является ни одной из только что описанных, вероятная причина проблем, в том что  БД MySQL  
  с данными GIS-системы активно использует BLOG-данные, размер которых  превышает параметр "max_allowed_packet",
  что может вызвать эту ошибку на некоторых клиентах. 
  Иногда вы можете увидеть "ER_NET_PACKET_TOO_LARGE" ошибку, и это подтверждает, 
  что нужно увеличить параметр "max_allowed_packet".

  Для этого необходимо внести абзац в файл конфигурации  my.cnf  

           [mysqld]
           max_allowed_packet=16M

  [https://stackoverflow.com/questions/7942154/mysql-error-2006-mysql-server-has-gone-away/9479681#9479681]

Еще  одной проблемой потери коннекта может явиться слишком долгое выполнение запросов.  
Одним из путей решения данной проблемы может стать перестроение индексов БД MySQL для оптимизации  

и ускорения запросов на основании плана запроса с помощью инструмента-профайлера EXPLAIN ANALYZE.


  [https://stackoverflow.com/questions/10563619/error-code-2013-lost-connection-to-mysql-server-during-query]
  

---
### Задача 4
- Перед выполнением задания ознакомьтесь со статьей "Common PostgreSQL errors"  
(https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors) .

- Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, 
что эта СУБД работает с большим объемом данных лучше, чем MySQL.
- После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. 
В dmesg вы видите, что:  ... postmaster invoked oom-killer

Как вы думаете, что происходит?
Как бы вы решили данную проблему?

---
### Ответ:
      
      Причина - в недостатке оперативной памяти на хосте, в результате ОС Linux c помощью процесса OOM-killer завершает процесс,
      максимально использующий память, чтобы предотвратить падение всей системы.
      Если вы получите уведомление о том, что произошло событие «недостаточно памяти», процесс OOM-killer уже выполнил свою работу, 
      и вы увидите, что память освобождена. Это указывает на то, что postgres процесс был завершен из-за нехватки памяти. 
      Хотя существующие соединения с базой данных будут продолжать нормально работать, 
      новые соединения приниматься не будут. Для восстановления PostgreSQL потребуется перезапустить.

      Ищем данное событие в файле лога 
      
      #  grep "Out of memory" /var/log/dmesg 

      Итак, чтобы выяснить, что произошло, нам придется просмотреть журналы
   
      #  less /var/log/kern.log|grep -v 'UFW BLOCK' 
      #  dmesg --ctime --color=always | grep -v 'UFW BLOCK'), чтобы узнать, что произошло.


      1)  Для предупреждения убийства процесса, для начала можно просто увеличить объем ОЗУ хоста. 
          или выставить ограничение в следующих параметрах настройки PostgreSQL на использование ОЗУ хоста : 
          -max_connections, 
          -shared_buffer         (в строке shared_buffers нужно указать около 75% оперативной памяти. )
          -work_mem              ( для GIS систем рекомендуется 16Mb) 
          -effective_cache_size, 
          -maintenance_work_mem  (увеличьте её значение до 25% от ОЗУ).

          Типичная причина переполнения используемой памяти  процессом PostgreSQL  - слишком большие величины  параметра work_mem  
          в файле конфигурации postgresql.conf. Его можно уменьшить.

      2) Вариантом решения нехватки памяти на хосте также может стать установка между клиентами 
         и CУБД PostgreSQL   сервиса  pgBouncer - пулера подключений (или connection pooler).  
         Postgres делает очень плохую вещь: на каждое соединение он создаёт настоящий процесс ОС, съедающий кусок ОЗУ.
         pgBouncer снизит количество одновременных коннектов на одну ноду, и, соответственно, требования к параметру max_connections,
         а также высвободит ОЗУ, использующуюся каждым новым процессом при очередном коннекте.    
   
      3) Если возможности добавить ОЗУ  на хост нет, то можно исключить процесс PostgreSQL из расстрельного списка OOO "Киллер". 
     
        - Сначала выясним идентификатор (PID) процесса postmaster:

        # pgrep -f postmaster
        3234.

        - Затем настраиваем  OOM Killer так, чтобы он спрятал пушку и не думал убить процесс с PID 3234 — записываем в файл oom_adj 
          в соответствующем каталоге (/proc/PID/oom_adj) магическое число -17 (OOM score):

        # echo -17 > /proc/3234/oom_adj 

        Также эти две команды можно добавить после команды запуска БД PostgreSQL в скрипте инициализации .  
        pid=`ps ax | grep "postmaster" | awk '{print $1}'`
        echo -17 > /proc/$pid/oom_adj 

        - Проверим заданные настройки:

        # cat  /proc/3234/oom_adj 
        -17 


    4) Еще вариант - изменить поведение ядра ОС таким образом, чтобы оно не « перехватывало » память. 
       Хотя этот параметр не предотвратит вызов OOM-killer, он значительно снизит эту вероятность и,
       следовательно, приведет  к более надежному поведению системы. 
       Это делается путем выбора строгого режима чрезмерной фиксации через sysctl:

        а) Выполение команды через консоль

           # sysctl -w vm.overcommit_memory = 2
      
        б) Добавление записи в файл конфигурации /etc/sysctl.conf

           sysctl -w vm.overcommit_memory = 2  ,
        
           где 2 — отказ обработки запросов, запрашивающих память, 
           размер которой превышает суммарный размер памяти пространства подкачки и ОЗУ в соответствии с overcommit_ratio.



=====================================================================
[https://postgrespro.ru/docs/postgresql/9.6/runtime-config-resource]
  
         work_mem (integer)
         Задаёт объём памяти, который будет использоваться для внутренних операций сортировки
         для ORDER BY, DISTINCT  и хеш-таблиц, прежде чем будут задействованы временные файлы на диске. 
         Значение по умолчанию — четыре мегабайта (4MB). 

